21/12/07 18:24:55 WARN NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/12/07 18:24:55 INFO SecurityManager - Changing view acls to: 1000650000
21/12/07 18:24:55 INFO SecurityManager - Changing modify acls to: 1000650000
21/12/07 18:24:55 INFO SecurityManager - Changing view acls groups to: 
21/12/07 18:24:55 INFO SecurityManager - Changing modify acls groups to: 
21/12/07 18:24:55 INFO SecurityManager - SecurityManager: authentication enabled; ui acls disabled; users  with view permissions: Set(1000650000); groups with view permissions: Set(); users  with modify permissions: Set(1000650000); groups with modify permissions: Set()
2021-12-07 18:24:56.692+0000 INFO: Job run ID: d16204f2-6093-4997-9125-5ca6c69b5b62
2021-12-07 18:24:56.709+0000 INFO: Loading libraries.
2021-12-07 18:24:56.730+0000 INFO: Running jsonlite v 1.7.2
2021-12-07 18:24:56.731+0000 INFO: Running dplyr v 0.8.2
2021-12-07 18:24:58.638+0000 INFO: Runtime environment: Spark
2021-12-07 18:24:58.638+0000 INFO: Initializing parameters for Data Refinery flow.
Spark package found in SPARK_HOME: /opt/ibm/spark
21/12/07 18:24:59 INFO SparkContext - Running Spark version 3.0.2
21/12/07 18:24:59 INFO ResourceUtils - ==============================================================
21/12/07 18:24:59 INFO ResourceUtils - Resources for spark.driver:

21/12/07 18:24:59 INFO ResourceUtils - ==============================================================
21/12/07 18:24:59 INFO SparkContext - Submitted application: SparkR
21/12/07 18:24:59 INFO SecurityManager - Changing view acls to: 1000650000
21/12/07 18:24:59 INFO SecurityManager - Changing modify acls to: 1000650000
21/12/07 18:24:59 INFO SecurityManager - Changing view acls groups to: 
21/12/07 18:24:59 INFO SecurityManager - Changing modify acls groups to: 
21/12/07 18:24:59 INFO SecurityManager - SecurityManager: authentication enabled; ui acls disabled; users  with view permissions: Set(1000650000); groups with view permissions: Set(); users  with modify permissions: Set(1000650000); groups with modify permissions: Set()
21/12/07 18:24:59 INFO Utils - Successfully started service 'sparkDriver' on port 37351.
21/12/07 18:24:59 INFO SparkEnv - Registering MapOutputTracker
21/12/07 18:25:00 INFO SparkEnv - Registering BlockManagerMaster
21/12/07 18:25:00 INFO BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/12/07 18:25:00 INFO BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
21/12/07 18:25:00 INFO SparkEnv - Registering BlockManagerMasterHeartbeat
21/12/07 18:25:00 INFO DiskBlockManager - Created local directory at /tmp/spark/scratch/blockmgr-cf159740-56c2-4439-a2fb-8b2f06b968ed
21/12/07 18:25:00 INFO MemoryStore - MemoryStore started with capacity 2.2 GiB
21/12/07 18:25:00 INFO SparkEnv - Registering OutputCommitCoordinator
21/12/07 18:25:00 INFO Utils - Successfully started service 'SparkUI' on port 4040.
21/12/07 18:25:00 INFO SparkUI - Bound SparkUI to 0.0.0.0, and started at http://spark-master-headless-d16204f2-6093-4997-9125-5ca6c69b5b62:4040
21/12/07 18:25:00 INFO SparkContext - Added file file:/opt/ibm/third-party/libs/exec/Runner3.R at spark://spark-master-headless-d16204f2-6093-4997-9125-5ca6c69b5b62:37351/files/Runner3.R with timestamp 1638901499527
21/12/07 18:25:00 INFO Utils - Copying /opt/ibm/third-party/libs/exec/Runner3.R to /tmp/spark/scratch/spark-b2fb9884-d45a-44c1-a58c-c28b6f7f1a70/userFiles-21038f5c-9d6f-4bd5-b430-0e743b545a30/Runner3.R
21/12/07 18:25:01 INFO StandaloneAppClient$ClientEndpoint - Connecting to master spark://10.254.25.27:7077...
21/12/07 18:25:01 INFO TransportClientFactory - Successfully created connection to /10.254.25.27:7077 after 282 ms (205 ms spent in bootstraps)
21/12/07 18:25:01 INFO StandaloneSchedulerBackend - Connected to Spark cluster with app ID app-20211207182501-0000
21/12/07 18:25:01 INFO Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39931.
21/12/07 18:25:01 INFO NettyBlockTransferService - Server created on spark-master-headless-d16204f2-6093-4997-9125-5ca6c69b5b62:39931
21/12/07 18:25:01 INFO BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/12/07 18:25:01 INFO BlockManagerMaster - Registering BlockManager BlockManagerId(driver, spark-master-headless-d16204f2-6093-4997-9125-5ca6c69b5b62, 39931, None)
21/12/07 18:25:01 INFO BlockManagerMasterEndpoint - Registering block manager spark-master-headless-d16204f2-6093-4997-9125-5ca6c69b5b62:39931 with 2.2 GiB RAM, BlockManagerId(driver, spark-master-headless-d16204f2-6093-4997-9125-5ca6c69b5b62, 39931, None)
21/12/07 18:25:01 INFO StandaloneAppClient$ClientEndpoint - Executor added: app-20211207182501-0000/0 on worker-20211207182449-10.254.32.187-37499 (10.254.32.187:37499) with 1 core(s)
21/12/07 18:25:01 INFO BlockManagerMaster - Registered BlockManager BlockManagerId(driver, spark-master-headless-d16204f2-6093-4997-9125-5ca6c69b5b62, 39931, None)
21/12/07 18:25:02 INFO StandaloneSchedulerBackend - Granted executor ID app-20211207182501-0000/0 on hostPort 10.254.32.187:37499 with 1 core(s), 4.0 GiB RAM
21/12/07 18:25:02 INFO StandaloneAppClient$ClientEndpoint - Executor added: app-20211207182501-0000/1 on worker-20211207182448-10.254.37.111-39633 (10.254.37.111:39633) with 1 core(s)
21/12/07 18:25:02 INFO StandaloneSchedulerBackend - Granted executor ID app-20211207182501-0000/1 on hostPort 10.254.37.111:39633 with 1 core(s), 4.0 GiB RAM
21/12/07 18:25:02 INFO BlockManager - Initialized BlockManager: BlockManagerId(driver, spark-master-headless-d16204f2-6093-4997-9125-5ca6c69b5b62, 39931, None)
21/12/07 18:25:02 INFO StandaloneAppClient$ClientEndpoint - Executor updated: app-20211207182501-0000/1 is now RUNNING
21/12/07 18:25:02 INFO StandaloneAppClient$ClientEndpoint - Executor updated: app-20211207182501-0000/0 is now RUNNING
21/12/07 18:25:02 INFO SingleEventLogFileWriter - Logging events to file:/home/spark/spark-events/app-20211207182501-0000.inprogress
21/12/07 18:25:02 INFO StandaloneSchedulerBackend - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
21/12/07 18:25:03 INFO HiveConf - Found configuration file null
21/12/07 18:25:03 INFO SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/spark/shared/spark-warehouse').
21/12/07 18:25:03 INFO SharedState - Warehouse path is 'file:/home/spark/shared/spark-warehouse'.
21/12/07 18:25:04 INFO SparkUI - Stopped Spark web UI at http://spark-master-headless-d16204f2-6093-4997-9125-5ca6c69b5b62:4040
21/12/07 18:25:04 INFO StandaloneSchedulerBackend - Shutting down all executors
21/12/07 18:25:04 INFO CoarseGrainedSchedulerBackend$DriverEndpoint - Asking each executor to shut down
21/12/07 18:25:04 INFO MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
21/12/07 18:25:04 INFO MemoryStore - MemoryStore cleared
21/12/07 18:25:04 INFO BlockManager - BlockManager stopped
21/12/07 18:25:04 INFO BlockManagerMaster - BlockManagerMaster stopped
21/12/07 18:25:04 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
21/12/07 18:25:04 INFO SparkContext - Successfully stopped SparkContext
2021-12-07 18:25:04.422+0000 INFO: Set additional spark config properties.
2021-12-07 18:25:04.422+0000 INFO: Spark master: spark://spark-master-headless-d16204f2-6093-4997-9125-5ca6c69b5b62:7077
2021-12-07 18:25:17.023+0000 INFO: Connected to Spark runtime environment.
2021-12-07 18:25:17.024+0000 INFO: R version 3.6.3 (2020-02-29)
2021-12-07 18:25:17.024+0000 INFO: Running Spark version 3.0.2
2021-12-07 18:25:17.027+0000 INFO: Running Sparklyr version 1.5.2
2021-12-07 18:25:17.156+0000 INFO: Running Arrow version 5.0.0
2021-12-07 18:25:17.157+0000 INFO: Registering UDFs.
2021-12-07 18:25:18.039+0000 INFO: Completed processing user info from authentication token.
2021-12-07 18:25:18.040+0000 INFO: Using service token for flow run.
2021-12-07 18:25:18.142+0000 INFO: Running ShaperFlowPkg version 5.2.3 (IMAGE:4.0.1049)
2021-12-07 18:25:18.142+0000 INFO: Running Connector version 5.0.288
2021-12-07 18:25:18.142+0000 INFO: Running UDF version 7.0.45
2021-12-07 18:25:18.142+0000 INFO: Number of partitions: 2
2021-12-07 18:25:18.222+0000 INFO: Reading Data Refinery flow: teststats.csv_flow
2021-12-07 18:25:18.223+0000 INFO: Creating Spark payload: Processing source and target properties, and operations.
2021-12-07 18:25:18.821+0000 INFO: Completed reading properties for 'source1': teststats.csv
2021-12-07 18:25:18.822+0000 INFO: Data source type: assetfiles
2021-12-07 18:25:18.822+0000 INFO: AvailMemBytes: 2576979723 Size: 654 Cache: TRUE
2021-12-07 18:25:32.944+0000 INFO: Completed reading properties for 'target1': teststats_csv_shaped
2021-12-07 18:25:32.944+0000 INFO: Data source type: assetfiles
2021-12-07 18:25:32.945+0000 INFO: Running Spark payload.
2021-12-07 18:25:54.230+0000 INFO: Time taken to run spark payload: 21 secs
2021-12-07 18:25:54.341+0000 INFO: Created data asset 'teststats_csv_shaped'.
2021-12-07 18:25:54.369+0000 INFO: Created attachment for 'teststats_csv_shaped'. 
2021-12-07 18:25:54.439+0000 INFO: Total execution time : 36 secs
2021-12-07 18:25:54.439+0000 INFO: Updating job run status to 'FINISHED'.
2021-12-07 18:25:54.439+0000 INFO: 6 rows read.
2021-12-07 18:25:54.439+0000 INFO: 511 bytes read.
2021-12-07 18:25:54.440+0000 INFO: 6 rows written.
2021-12-07 18:25:54.440+0000 INFO: 511 bytes written.
Warning messages:
1: replacing previous import ‘lubridate::union’ by ‘dplyr::union’ when loading ‘ShaperFlowPkg’ 
2: replacing previous import ‘lubridate::intersect’ by ‘dplyr::intersect’ when loading ‘ShaperFlowPkg’ 
3: replacing previous import ‘lubridate::setdiff’ by ‘dplyr::setdiff’ when loading ‘ShaperFlowPkg’ 
4: package ‘SparkR’ was built under R version 4.0.3 
21/12/07 18:25:57 INFO ShutdownHookManager - Shutdown hook called
21/12/07 18:25:57 INFO ShutdownHookManager - Deleting directory /tmp/spark/scratch/spark-b2fb9884-d45a-44c1-a58c-c28b6f7f1a70
2021-12-07 18:25:57,831 Thread-4 WARN Unable to register Log4j shutdown hook because JVM is shutting down. Using SimpleLogger
